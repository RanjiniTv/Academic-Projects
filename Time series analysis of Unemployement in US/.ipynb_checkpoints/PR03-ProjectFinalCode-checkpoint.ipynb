{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6de454b8e379477f0b24d4aeb46b54f",
     "grade": false,
     "grade_id": "cell-ea1356fb2fa161a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Project Final Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c13f0fb473d6c832136a348847c3d245",
     "grade": true,
     "grade_id": "cell-520b9a1998578280",
     "locked": false,
     "points": 0.1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "**Title:** Time series analysis of state- and county-level unemployment rates in the USA\n",
    "\n",
    "**Index:**  \n",
    "[Obtaining the Data](#-Obtaining-the-Data)  \n",
    "[Setup](#Setup)  \n",
    "[Data Preparation](#Data-Preparation)   \n",
    "[Data Exploration](#Data-Exploration)  \n",
    "[Modeling](#Modeling) \n",
    "[Presentation Graphic(s)](#Presentation-Graphic(s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8afa10661e34a7e5d2ac29a291d29af8",
     "grade": false,
     "grade_id": "cell-259aa4719392cc9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Obtaining the Data\n",
    "The data required for this project may be obtained as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e9e40aaf5be6e8697f52969f9bf1edc",
     "grade": true,
     "grade_id": "cell-5d0765799a830601",
     "locked": false,
     "points": 0.1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "The source of datasets\n",
    "- 'unemployment-by-county-us.csv': https://www.kaggle.com/jayrav13/unemployment-by-county\n",
    " (dowload output.csv)\n",
    "- 'Unemployment.csv': https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/ (dowload file for 'Unemployment and median household income for the U.S., States, and counties, 2007-18')\n",
    "- 'states.csv' and 'Counties.csv': https://www.kaggle.com/stansilas/us-state-county-name-codes#US%20Countiess.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24df493960920d9ea471708f06fbace8",
     "grade": false,
     "grade_id": "cell-8770d1ab57c81792",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib notebook\n",
    "# mainline tools\n",
    "import os\n",
    "import re\n",
    "# data tools\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import scipy  as sp\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "# plotting and graphics\n",
    "import matplotlib        as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates  as mdates\n",
    "import mplleaflet \n",
    "# Use seaborn theme, scaling, and color palette.\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "# %matplotlib inline\n",
    "# sns.set_context('notebook')\n",
    "# from IPython.core.pylabtools import figsize\n",
    "# #@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)\n",
    "# notebook_screen_res = 'retina' #@param ['retina', 'png', 'jpeg', 'svg', 'pdf']\n",
    "# %config InlineBackend.figure_format = notebook_screen_res\n",
    "sns.set()\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 9, \"ytick.major.size\": 9})\n",
    "rcParams['figure.figsize'] = 15.7,8.27\n",
    "plt.style.use('seaborn-ticks')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] =20\n",
    "\n",
    "\n",
    "# Styling seems more consistent if set using MPL instead of sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Set paths to directories for the data\n",
    "dataroot = os.environ['HOMESHARE']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "619970a9d0e740b6cbcd0f1cbc67b906",
     "grade": false,
     "grade_id": "cell-5864d3b3e792fc82",
     "locked": true,
     "points": 1.1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been loaded from different sources and merged to a single dataframe.Below mentioned utility functions are used at different stages of data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "\n",
    "\n",
    "def calc_rate(df):\n",
    "    '''To calculate unemployment rate while aggregating'''\n",
    "    df['Unemployment Rate (%)']=((df['Unemployed']/df['Civilian_labor_force'])*100)\n",
    "    df.drop(['Civilian_labor_force','Unemployed'],axis=1)\n",
    "    #df.set_index('Year',inplace=True)\n",
    "    return df\n",
    "\n",
    "def return_date(year, month):\n",
    "    '''combine month and year to form date'''\n",
    "    months = {\"january\":0, \"february\":1, \"march\":2, \"april\":3, \"may\":4, \"june\":5, \"july\":6, \"august\":7, \"september\":8, \"october\":9, \"november\":10, \"december\":11 }\n",
    "    # print(months[month.lower()]+1)\n",
    "    return(datetime.datetime(year, months[month.lower()]+1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to load and merge datasets \n",
    "def load_df( DataDir ):\n",
    "    '''Loading main dataset'''\n",
    "    # Read the data into a Pandas dataframe \n",
    "    df=pd.read_csv(os.path.join(DataDir,'unemployment-by-county-us.csv'))\n",
    "    \n",
    "    #adding state abbr and FIPS code\n",
    "    state=pd.read_csv(\"states.csv\",dtype=str)\n",
    "    fips=pd.read_csv(\"Counties.csv\",dtype=str)\n",
    "    df=df.merge(state,on ='State').merge(fips,left_on=['Abbreviation','County'],right_on=['X1','X4']).sort_values(by=['Year','Month','State','County'])\n",
    "    df['FIPS']=df[\"X2\"].map(str) + df[\"X3\"].map(str)\n",
    "    df=df[['Year','Month','X2','Abbreviation','County','FIPS','Rate']]\n",
    "    df.columns=['Year','Month','State_code','State','County','FIPS','Unemployment_Rate']\n",
    "    return df\n",
    "\n",
    "def load_pop(DataDir):\n",
    "    '''Loding second datset containing Civilian_Labour_Force'''\n",
    "    df1=pd.read_csv(\"Unemployment.csv\",usecols=[x for x in range(56) if x not in [3,4,5,54,55,56]] )\n",
    "    #removing unwanted records\n",
    "    df1=df1.loc[~df1.FIPS.isin([x for x in df1.FIPS if str(x).endswith(\"000\")])]\n",
    "    df1=df1[df1['State']!='US']\n",
    "    df1['FIPS'] = df1['FIPS'].astype(str)\n",
    "    #making FIPS code 5digits\n",
    "    df1['FIPS']=df1['FIPS'].str.rjust(5,'0')\n",
    "    labour_force=df1.loc[:,(['FIPS','State','Area_name']+[x for x in df1.columns if x.strip().startswith(\"Civilian_labor_force\")])]\n",
    "    employed=df1.loc[:,(['FIPS','State','Area_name']+[x for x in df1.columns if x.strip().startswith(\"Employed\")])]\n",
    "    unemployed=df1.loc[:,(['FIPS','State','Area_name']+[x for x in df1.columns if x.strip().startswith(\"Unemployed\")])]\n",
    "    #ordering of columns\n",
    "    def reorder(data,string):\n",
    "        '''Rearranging df columns'''\n",
    "        data.Area_name= data.Area_name.str.split(',').str[0]\n",
    "        data.columns = data.columns.str.strip()\n",
    "        data.columns=['FIPS','State','County',2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018]\n",
    "        data[data.columns[3:]]=data[data.columns[3:]].apply(lambda x: pd.to_numeric(x.astype(str).str.replace(',',''), errors='coerce'))\n",
    "        data=data.set_index(['FIPS','State','County']).stack()\n",
    "        data.name=string\n",
    "        data.index.names=['FIPS','State', 'County', 'Year']\n",
    "        data=data.reset_index()\n",
    "        data=data.reset_index(drop=True)\n",
    "        return data\n",
    "    df1=reorder(labour_force,'Civilian_labor_force')\n",
    "    df1.dropna(inplace=True)\n",
    "    return df1\n",
    "\n",
    "def prepare_data(df):\n",
    "    df=df[['Year','Month','State_code','State','County','FIPS','Civilian_labor_force','Unemployment_Rate']]\n",
    "    #finding out monthly unemployed value based on civilian labour force and unemployment rate\n",
    "    df['Unemployed']=(df['Civilian_labor_force']*df['Unemployment_Rate']/100).round()\n",
    "    #checking for duplicates\n",
    "    df[df.duplicated(subset=['Year','Month','State','FIPS'])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataDir = os.path.join(dataroot, 'project')\n",
    "#reading main data file\n",
    "df=load_df(DataDir)\n",
    "\n",
    "#loading civilian labour force data \n",
    "df2=load_pop(DataDir)\n",
    "\n",
    "#merge main data with civilian labour force\n",
    "data_all=df.merge(df2,on=['Year','State','FIPS'],suffixes=(\"\",\"_\"))\n",
    "\n",
    "\n",
    "#cleaning\n",
    "data_all= prepare_data(data_all)\n",
    "data_all.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a0e480232550900366ae2fc89b3dc39",
     "grade": false,
     "grade_id": "cell-141a2bb87d84a15e",
     "locked": true,
     "points": 1.2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has following attributes and datatypes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary statistics of the dataset is as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "Histograms are plotted both on county level and state level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_county(data_all):\n",
    "    '''Plots histogram on County unemployment(monthly for each year) '''\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.distplot(data_all['Unemployment_Rate'])\n",
    "    plt.xlabel(\"Unemployment Rate (%)\", fontsize=15)\n",
    "    plt.ylabel(\"Frequency\",fontsize=15)\n",
    "    plt.title(\"Histogram on county level unemployment rate\",fontsize=20)\n",
    "    plt.show()\n",
    "def plot_hist_state(dfs):\n",
    "    '''Plots histogram on County unemployment(monthly for each year) '''\n",
    "    dfs_m=calc_rate(dfs)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.distplot(dfs['Unemployment Rate (%)'])\n",
    "    plt.xlabel(\"Unemployment Rate (%)\", fontsize=15)\n",
    "    plt.ylabel(\"Frequency\",fontsize=15)\n",
    "    plt.title(\"Histogram on State average unemployment rate\",fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_county(data_all)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram on county level shows some extreme values  causing long tail. Aggregating data statewise to see the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram on state unemployment(monthly for each year) \n",
    "#satewise average\n",
    "\n",
    "dfs=data_all.groupby(['Year','Month','State_code','State'],as_index=False).mean()\n",
    "df_state=dfs.groupby(['State'],as_index=False).mean()\n",
    "df_state=calc_rate(df_state)[['State','Civilian_labor_force','Unemployment Rate (%)']]\n",
    "df_state1=df_state[['State','Unemployment Rate (%)']]\n",
    "\n",
    "plot_hist_state(dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is pretty well distributed with mean value around 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for outliers\n",
    "In order to check for the outliers,plotted boxplot and it is seen that outliers are negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = dfs['Year'], y = dfs['Unemployment Rate (%)'])\n",
    "plt.title(\"Box Plot of Yearly Unemployment Rate\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Month and Year can be combined to form Date.\n",
    "data_all_ts=data_all.copy()\n",
    "data_all_ts['Date']=data_all_ts.apply(lambda x: return_date(x['Year'], x['Month']), axis=1)\n",
    "data_all_ts=data_all_ts.sort_values(by='Date')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing datetimeindex values based on reference index (with all values)\n",
    "data_all_ts.set_index('Date')['State'].groupby('Date').count().plot(figsize = (16,6))\n",
    "\n",
    "finding number of counties with missing data.For 10 years it need 120 records for each county)\n",
    "FIPS=(data_all_ts.groupby(['FIPS','Date']).count()['Unemployed'].groupby(['FIPS']).count())!=120\n",
    "FIPS[FIPS==True]#662 counties doesnt have data for all the month and year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzed county level, there are 662 counties with missing values(doesn't have values for all the month and year). Then I aggregated data on State level and checked if all values present for all the month and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "finding number of states with missing data(For 10 years it need 120 records for each state)\n",
    "St=(data_all_ts.groupby(['State','Date']).count()['Unemployed'].groupby(['State']).count())!=120\n",
    "St[St==True]#6 states doesnt have data for all the month and year\n",
    "CA    101,KY     99,LA     76,MI     88,TX     83,VA     98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 states with missing data. It needs to be filled before modelling. \n",
    "\n",
    "For further analysis, data has been plotted at ditfferent levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County level analysis\n",
    "\n",
    "The overall geoplot has been plotted to get an idea about rate at county level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to install geopy plotly\n",
    "# !pip install geopy plotly --user\n",
    "# !pip install plotly-geo --user\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_geo(df,title):\n",
    "    '''Plots choropleth graph to display unemployment rate at county level '''\n",
    "    colorscale = [\"#f7fbff\",\"#ebf3fb\",\"#deebf7\",\"#d2e3f3\",\"#c6dbef\",\"#b3d2e9\",\"#9ecae1\",\n",
    "              \"#85bcdb\",\"#6baed6\",\"#57a0ce\",\"#4292c6\",\"#3082be\",\"#2171b5\",\"#1361a9\",\n",
    "              \"#08519c\",\"#0b4083\",\"#08306b\"]\n",
    "    endpts = list(np.linspace(1, 12, len(colorscale) - 1))\n",
    "    df=df.sort_values(by='FIPS')\n",
    "    fips = df['FIPS'].tolist()\n",
    "    values = df['Unemployment Rate (%)'].tolist()\n",
    "\n",
    "    fig = ff.create_choropleth(\n",
    "        fips=fips, values=values,\n",
    "        binning_endpoints=endpts,\n",
    "        colorscale=colorscale,\n",
    "        show_state_data=True,\n",
    "        show_hover=True, centroid_marker={'opacity': 0},\n",
    "        asp=2.9, title=title,\n",
    "        legend_title='% unemployed'\n",
    "    )\n",
    "\n",
    "    fig.layout.template = None\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_county=data_all.copy()\n",
    "#overall unemployment rate for each county\n",
    "df_county1=df_county.groupby(['FIPS'],as_index=False).mean()[['FIPS','Civilian_labor_force','Unemployed']]\n",
    "df_county1=calc_rate(df_county1)[['FIPS','Unemployment Rate (%)']]\n",
    "\n",
    "\n",
    "plot_geo(df_county1,'Overall Unemployment rate in US by county')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots it is clearly visible unemployment rate more towards east coast and west coast regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statewise anlysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Geographical location and Unemployment_Rate, I have selected 5 states (ND,MI,WA,NY and CA,) for further analysis. This selection has been done based on the civilian labour force and geographical location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig3(dfs): \n",
    "    '''Plots area stacked plot for the selected five states'''\n",
    "    states=['ND','WA','MI','NY','CA']\n",
    "    dfs=dfs.groupby(['Year','State_code','State'],as_index=False).mean()\n",
    "    dfs=calc_rate(dfs)[['Year','State','Unemployment Rate (%)']]\n",
    "    df_states5=dfs[dfs['State'].isin(states)].sort_values(by=['State','Year'])\n",
    "    df_states5=df_states5.pivot(index='Year', columns='State')\n",
    "    plt.style.use('seaborn')\n",
    "    df_states5.plot.area(alpha=0.5)\n",
    "    fig= plt.gcf()\n",
    "    fig.set_size_inches(15,10) \n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.legend(loc=1)\n",
    "    plt.title(\"Unemployment rate analysis for selected states(2007-16)\",fontsize=20)\n",
    "    plt.show()\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_fig3(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area chart shows \"Unemployment_Rate\" change over the same period for the above chosen different states. Since data is stacked on top of another, it is much easier to compare how data is evolved over the time period. Among these 5 states, CA is one of the high \"Unemployment_Rate\" state, ND with least, and NY with average. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data distribution analysis for the selected states\n",
    "Here I have used violin plot in order to understand the distribution of underlying data in a state by taking examples as 'ND','WA','MI','NY' and 'CA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin(df,state,ax):\n",
    "    '''Plots violin plot for the selected five states in order to understand underlying data distribution'''\n",
    "    state_names=['North Dakota','Washington','Michigan','New York','California']\n",
    "    states=['ND','WA','MI','NY','CA']\n",
    "    state_dict = dict(zip(states,state_names))\n",
    "    out=df[df.State==state]\n",
    "    #print(out)\n",
    "    out=out.groupby(['Year','FIPS'],as_index=False).mean()[['Year','FIPS','Civilian_labor_force','Unemployed']].round()\n",
    "    out=calc_rate(out)[['Year','FIPS','Unemployment Rate (%)']]\n",
    "    #print(out)\n",
    "    sns.violinplot( ax=ax,x = out['Year'], y = out['Unemployment Rate (%)'],inner=\"box\") \n",
    "    ax.set_title(state_dict[state])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig3, axs3 = plt.subplots(num=3, nrows=5,sharex=True, ncols=1,figsize=[10,20], dpi=100, clear=True)\n",
    "\n",
    "states=['ND','WA','MI','NY','CA']\n",
    "for i in range(len(states)):\n",
    "    plot_violin(df_county,states[i],axs3[i])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig3.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analyzing violin plot for ND, we can see that the mean is almost constant across the years, and distribution is almost constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd744aac8dbd1e06bdf48a27c51b783a",
     "grade": false,
     "grade_id": "cell-01669f3b88a0d3c0",
     "locked": true,
     "points": 1.4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the analysis done above ,I have selected two states ND and CA for modelling, which represents states with low and high civilian labour force. Also,ND has least deviation in the distribution,and no missing data. CA has few missing data, which can be filled with interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Month and Year can be combined to form DateTimeIndex.\n",
    "data_all_ts=data_all.copy()\n",
    "data_all_ts['Date']=data_all_ts.apply(lambda x: return_date(x['Year'], x['Month']), axis=1)\n",
    "data_all_ts=data_all_ts.sort_values(by='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ts(df,St_code):\n",
    "    '''generate time series data'''\n",
    "    df['Date']=df.apply(lambda x: return_date(x['Year'], x['Month']), axis=1)\n",
    "    df['Unemployed']=df['Unemployed'].round() \n",
    "    df=df[['Date','State_code','Unemployed']].sort_values(by=['Date','State_code'])\n",
    "    ts=df[df.State_code==St_code][['Date','Unemployed']]\n",
    "    ts=ts.set_index('Date')\n",
    "    return ts\n",
    "def check_correlation(df):\n",
    "    '''Check if there is any correlation between the current data and previous data'''\n",
    "    #lag plot\n",
    "    lag_plot(df)\n",
    "    plt.show()\n",
    "    \n",
    "    #autocorrelation plot\n",
    "    autocorrelation_plot(df)\n",
    "    plt.title('Autocorrelation plot',fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #correlation matrix\n",
    "    values = pd.DataFrame(df.values)\n",
    "    dataframe = concat([values.shift(1), values], axis=1)\n",
    "    dataframe.columns = ['t-1', 't+1']\n",
    "    result = dataframe.corr()\n",
    "    print(result)\n",
    "\n",
    "def seasonal_decomp(df):\n",
    "    '''Data is decomposed into seasonal and trend .We need to remove data out of it'''\n",
    "    result = seasonal_decompose(df, model='multiplicative')\n",
    "    result.plot()\n",
    "    plt.show()\n",
    "def modeling(df,lag):\n",
    "    X = df.values\n",
    "    size = int(len(X) * 0.66)\n",
    "    train, test = X[0:size], X[size:len(X)]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    test = scaler.transform (test)\n",
    "\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=(lag,1,0))\n",
    "        model_fit = model.fit(disp=0)\n",
    "        output = model_fit.forecast()\n",
    "        yhat = output[0]\n",
    "        predictions.append(yhat)\n",
    "        obs = test[t]\n",
    "        history.append(obs)\n",
    "        print('predicted=%f, expected=%f' % (yhat, obs))\n",
    "    error = mean_squared_error(test, predictions)\n",
    "    print('Test MSE: %.3f' % error)\n",
    "    # plot\n",
    "    plt.plot(test)\n",
    "    plt.plot(predictions, color='red')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Modelling for NorthDacota(ND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import concat\n",
    "from pandas.plotting import lag_plot\n",
    "#ND state code=46\n",
    "#preparing data for time series analysis-\n",
    "df_ts=dfs.copy()\n",
    "\n",
    "ts1=prepare_ts(df_ts,'46')\n",
    "check_correlation(ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_decomp(ts1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnning may take few minutes\n",
    "lag=9\n",
    "modeling(ts1,lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling for California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data_interploate(df):\n",
    "    #missing data handling\n",
    "    date_range = pd.date_range('2007-01-01',end= '2016-12-01', freq='MS')\n",
    "    df= df.loc[date_range, ['Unemployed']].copy()\n",
    "    df['Unemployed'].interpolate(method='time', inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CA state code=06\n",
    "# CA has missing records .So handled seperately. Interpolation has been done to fill missing data\n",
    "\n",
    "CA=prepare_ts(df_ts,'06')\n",
    "CA_1=missing_data_interploate(CA)\n",
    "CA_1=CA_1['Unemployed'].to_frame()\n",
    "ts2=CA_1\n",
    "check_correlation(ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_decomp(ts2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnning may take few minutes\n",
    "lag=15\n",
    "modeling(ts2,lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0a6b173e8037516e67ca3d0099d094d",
     "grade": false,
     "grade_id": "cell-e433e71229b731e8",
     "locked": true,
     "points": 1.4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Presentation Graphic(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Average State Unemployement Rate in the USA(2007-2016) \n",
    "The below map represents the average unemployment rate in each state in the USA. The bubble size represents the average unemployment rate for a state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actually it is an interactive plot with hover values as state name,longitude and latitude. But it needs large dataset(>300k)\n",
    "def geo_bubble(df_state1):\n",
    "    '''Plots bubble plot over geomap to represent rate in each state'''\n",
    "    states_all=df_state1[\"State\"].unique()\n",
    "    avg_unemp_rate_dict= dict(zip(sorted(list(states_all)), list(df_state1['Unemployment Rate (%)'])))\n",
    "    #getting the hover values\n",
    "    geolocator =Nominatim(user_agent=\"my-application\")\n",
    "    lati = []\n",
    "    longi = []\n",
    "    marker_size = []\n",
    "    text_list = []\n",
    "    for state in states_all:\n",
    "        loc = geolocator.geocode(state+','+ 'USA')\n",
    "        lati.append(loc.latitude)\n",
    "        longi.append(loc.longitude)\n",
    "        marker_size.append(avg_unemp_rate_dict[state]*5)\n",
    "        text_list.append(state + ':' + str(avg_unemp_rate_dict[state]))\n",
    "    fig = go.Figure(data=go.Scattergeo(\n",
    "            lon = longi,\n",
    "            lat = lati,\n",
    "            text = text_list,\n",
    "            mode = 'markers',\n",
    "            marker_size = marker_size\n",
    "            ))\n",
    "\n",
    "    fig.update_layout(\n",
    "            title = 'Average State Unemployement Rate in the USA(2007-2016)',\n",
    "            geo_scope='usa',\n",
    "        )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  geopy.geocoders import Nominatim\n",
    "import plotly.graph_objects as go\n",
    "geo_bubble(df_state1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Change in unemployment rate during different duration (2007-2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate at county level within a duration\n",
    "def county_year(df,start,end):\n",
    "    '''Filter out data between two years and aggregates'''\n",
    "    out=df[np.logical_and(df['Year']>=start , df['Year']<=end)]\n",
    "    out=out.groupby(['FIPS'],as_index=False).mean()[['FIPS','Civilian_labor_force','Unemployed']]\n",
    "    out=calc_rate(out)[['FIPS','Unemployment Rate (%)']]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_county_2007_09=county_year(df_county,2007,2009)\n",
    "df_county_2010_12=county_year(df_county,2010,2012)\n",
    "df_county_2013_15=county_year(df_county,2013,2015)\n",
    "plot_geo(df_county_2007_09,'Unemployment rate in US by county during 2007-09')\n",
    "plot_geo(df_county_2010_12,'Unemployment rate in US by county during 2010-12')\n",
    "plot_geo(df_county_2013_15,'Unemployment rate in US by county during 2013-15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Better performed states Vs Worst performed states during the period 2006-2017\n",
    "This graph gives an idea about the average unemployment rate in three best states and three worst states along with the national average rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bestworst(dfs):\n",
    "    '''Plots three best performed and worst performed states during this decade'''\n",
    "    df_state_2007=dfs[dfs.Year==2007].groupby(['Year','State'],as_index=False).mean()\n",
    "    df_state_2007=calc_rate(df_state_2007)[['Year','State','Unemployment Rate (%)']].set_index('State')\n",
    "\n",
    "    df_state_2016=dfs[dfs.Year==2016].groupby(['Year','State'],as_index=False).mean()\n",
    "    df_state_2016=calc_rate(df_state_2016)[['Year','State','Unemployment Rate (%)']].set_index('State')\n",
    "    change=(df_state_2016['Unemployment Rate (%)']-df_state_2007['Unemployment Rate (%)']).sort_values().dropna()\n",
    "    top_st=change.head(3).index\n",
    "    bottom_st=change.tail(3).index\n",
    "\n",
    "    worst=dfs[dfs['State'].isin(bottom_st)]\n",
    "    worst['Date']=worst.apply(lambda x: return_date(x['Year'], x['Month']), axis=1)\n",
    "\n",
    "    worst=calc_rate(worst)\n",
    "    worst=worst[['Date','State','Unemployment Rate (%)']]\n",
    "    worst = worst.reset_index(drop=True)\n",
    "\n",
    "    best=dfs[dfs['State'].isin(top_st)]\n",
    "    best['Date']=best.apply(lambda x: return_date(x['Year'], x['Month']), axis=1)\n",
    "\n",
    "    best=calc_rate(best)\n",
    "    best=best[['Date','State','Unemployment Rate (%)']]\n",
    "    best = best.reset_index(drop=True)\n",
    "    best.columns = [\"Date\", \"Better Perf States\", 'Unemployment Rate (%)']\n",
    "    worst.columns = [\"Date\", \"Worst Perf States\", 'Unemployment Rate (%)']\n",
    "\n",
    "    #US average\n",
    "    data_us=data_all.groupby(['Year','Month'],as_index=False).mean()[['Year','Month','Civilian_labor_force','Unemployed']]\n",
    "    data_us=calc_rate(data_us)[['Year','Month','Unemployment Rate (%)']]\n",
    "    data_us['Date']=data_us.apply(lambda x: return_date(x['Year'], x['Month']), axis=1)\n",
    "    data_us=data_us.sort_values(by='Date')\n",
    "    data_us.set_index('Date',inplace=True)\n",
    "    data_us=data_us['Unemployment Rate (%)']\n",
    "    data_us = pd.DataFrame(data_us)\n",
    "    data_us.columns = [\"National mean Unemployment Rate (%)\"]\n",
    "\n",
    "    # figure size in inches\n",
    "    rcParams['figure.figsize'] = 15.7,8.27\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "    sns.scatterplot(data=best,palette='BuGn_r',y=\"Unemployment Rate (%)\", x=\"Date\", hue=\"Better Perf States\",  alpha=.9)\n",
    "    sns.scatterplot(data=worst,palette='OrRd',y=\"Unemployment Rate (%)\", x=\"Date\", hue=\"Worst Perf States\", alpha=.9)\n",
    "    sns.lineplot(data=data_us,palette='PuBuGn_d',ci=0, linewidth=2.5)\n",
    "    plt.xlim(\"2006-11-11\" , \"2017-01-01\")\n",
    "    plt.title(\"Better performed states Vs Worst performed states during the period 2006-2017 \",fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bestworst(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Average Unemployment rate and Civilian Labour Force by states in US(2007-2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Unemployment rate and Civilian Labour Force by states in US(2007-2016)\n",
    "def plot_fig4(df_state):\n",
    "    '''Comparison on each states unemployment rate with Civilian labour force'''\n",
    "    fig, ax = plt.subplots(figsize=(20,7),sharex=True)\n",
    "    ax1 = ax.twinx()\n",
    "    sns.barplot(df_state.State, df_state['Unemployment Rate (%)'], alpha=0.2,color='blue',ax=ax,label='Average Unemployment rate')\n",
    "    sns.lineplot(x=df_state.State,y=df_state['Civilian_labor_force'],ax=ax1,color='black',label='Average Civilian Labour Force')\n",
    "    ax.set_xticklabels(df_state.State,rotation=70)\n",
    "    ax.grid(False)\n",
    "    ax1.grid(False)\n",
    "    plt.title(\"Average Unemployment rate and Civilian Labour Force by states in US(2007-2016)\",fontsize=20)\n",
    "    plt.xlabel('State Names')\n",
    "    ax.set_ylabel(\"Average Unemployment Rate\")\n",
    "    ax1.set_ylabel(\"Average Civilian Labour Force\")\n",
    "    ax1.lines[0].set_linestyle(\"--\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_fig4(df_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Yearly Unemployment Average and Min-Max Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotted year wise average unemployment rate along with the min-max band\n",
    "def plot_minmax(dfs):\n",
    "    '''Plots average unemployment rate along with the min-max band '''\n",
    "    dfs_x=dfs.groupby(['Year']).mean()\n",
    "    dfs_x_max=dfs.groupby(['Year']).max()\n",
    "    dfs_x_min=dfs.groupby(['Year']).min()\n",
    "    dfs_1=dfs.set_index('Year')\n",
    "    sns.lineplot(x=dfs_x.index, y=dfs_x['Unemployment Rate (%)'])\n",
    "    plt.fill_between(dfs_x.index, dfs_x_min['Unemployment Rate (%)'], dfs_x_max['Unemployment Rate (%)'], color='g', alpha=0.3)\n",
    "    plt.xticks(dfs_x.index, list(np.arange(2007, 2017)))\n",
    "    plt.ylim(0,20)\n",
    "    plt.grid(1)\n",
    "    plt.title('Yearly Unemployment Average and Min-Max Band', fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_minmax(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clearly visible that the unemployment rate is high in 2009-10 which is the recession period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "481aeabfd3a0aaff418e1abcfd034be3",
     "grade": false,
     "grade_id": "cell-c075a70ffbe9d335",
     "locked": true,
     "points": 1.2,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Project approach and overall execution\n",
    "Do not put anything below this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "643f1212dcfc2dbdc10f9965715144d3",
     "grade": false,
     "grade_id": "cell-307d558ea349391a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Code Structure and Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b36e1b21a5c9acc76ad001762eff01f",
     "grade": false,
     "grade_id": "cell-6a61ae6d12087891",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "## Code Commenting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
